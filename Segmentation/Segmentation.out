Device: cuda
* Epoch 1/30
 - loss: 0.654517
 - val_loss: 0.819867
* Epoch 2/30
 - loss: 0.611154
 - val_loss: 0.727069
* Epoch 3/30
 - loss: 0.602789
 - val_loss: 0.852422
* Epoch 4/30
 - loss: 0.496983
 - val_loss: 1.263368
* Epoch 5/30
 - loss: 0.462838
 - val_loss: 0.951802
* Epoch 6/30
 - loss: 0.427216
 - val_loss: 0.660250
* Epoch 7/30
 - loss: 0.413174
 - val_loss: 0.723999
* Epoch 8/30
 - loss: 0.366982
 - val_loss: 0.946456
* Epoch 9/30
 - loss: 0.350266
 - val_loss: 1.052549
* Epoch 10/30
 - loss: 0.361774
 - val_loss: 1.259668
* Epoch 11/30
 - loss: 0.353554
 - val_loss: 0.825512
* Epoch 12/30
 - loss: 0.320126
 - val_loss: 0.692332
* Epoch 13/30
 - loss: 0.279909
 - val_loss: 1.453946
* Epoch 14/30
 - loss: 0.273714
 - val_loss: 0.656926
* Epoch 15/30
 - loss: 0.215406
 - val_loss: 0.962583
* Epoch 16/30
 - loss: 0.236119
 - val_loss: 0.437819
* Epoch 17/30
 - loss: 0.211810
 - val_loss: 0.629936
* Epoch 18/30
 - loss: 0.186695
 - val_loss: 0.601117
* Epoch 19/30
 - loss: 0.175880
 - val_loss: 0.842799
* Epoch 20/30
 - loss: 0.187328
 - val_loss: 0.679983
* Epoch 21/30
 - loss: 0.171028
 - val_loss: 0.526328
* Epoch 22/30
 - loss: 0.152365
 - val_loss: 0.699072
* Epoch 23/30
 - loss: 0.154433
 - val_loss: 0.563723
* Epoch 24/30
 - loss: 0.155514
 - val_loss: 0.459364
* Epoch 25/30
 - loss: 0.167826
 - val_loss: 0.428165
* Epoch 26/30
 - loss: 0.136167
 - val_loss: 0.605286
* Epoch 27/30
 - loss: 0.145532
 - val_loss: 0.425067
* Epoch 28/30
 - loss: 0.132881
 - val_loss: 0.472636
* Epoch 29/30
 - loss: 0.126654
 - val_loss: 0.529656
* Epoch 30/30
 - loss: 0.125845
 - val_loss: 0.575043
* Epoch 1/30
 - loss: 0.578213
 - val_loss: 0.891927
* Epoch 2/30
 - loss: 0.507586
 - val_loss: 0.899658
* Epoch 3/30
 - loss: 0.453511
 - val_loss: 0.784685
* Epoch 4/30
 - loss: 0.404750
 - val_loss: 0.587074
* Epoch 5/30
 - loss: 0.337395
 - val_loss: 0.637852
* Epoch 6/30
 - loss: 0.291117
 - val_loss: 1.306289
* Epoch 7/30
 - loss: 0.273993
 - val_loss: 0.527627
* Epoch 8/30
 - loss: 0.226766
 - val_loss: 0.782363
* Epoch 9/30
 - loss: 0.214508
 - val_loss: 0.607167
* Epoch 10/30
 - loss: 0.196647
 - val_loss: 0.791182
* Epoch 11/30
 - loss: 0.186662
 - val_loss: 0.657341
* Epoch 12/30
 - loss: 0.165960
 - val_loss: 0.689553
* Epoch 13/30
 - loss: 0.167585
 - val_loss: 0.635003
* Epoch 14/30
 - loss: 0.148113
 - val_loss: 0.619016
* Epoch 15/30
 - loss: 0.149380
 - val_loss: 0.610173
* Epoch 16/30
 - loss: 0.137373
 - val_loss: 0.650500
* Epoch 17/30
 - loss: 0.140683
 - val_loss: 0.451408
* Epoch 18/30
 - loss: 0.138013
 - val_loss: 0.655164
* Epoch 19/30
 - loss: 0.126284
 - val_loss: 0.768251
* Epoch 20/30
 - loss: 0.129167
 - val_loss: 0.508810
* Epoch 21/30
 - loss: 0.130063
 - val_loss: 0.421494
* Epoch 22/30
 - loss: 0.137013
 - val_loss: 0.464689
* Epoch 23/30
 - loss: 0.150755
 - val_loss: 0.842604
* Epoch 24/30
 - loss: 0.135644
 - val_loss: 0.779210
* Epoch 25/30
 - loss: 0.141678
 - val_loss: 0.528897
* Epoch 26/30
 - loss: 0.137606
 - val_loss: 0.617138
* Epoch 27/30
 - loss: 0.131331
 - val_loss: 0.490411
* Epoch 28/30
 - loss: 0.132429
 - val_loss: 0.477313
* Epoch 29/30
 - loss: 0.130865
 - val_loss: 0.435359
* Epoch 30/30
 - loss: 0.123265
 - val_loss: 0.833039

------------------------------------------------------------
Sender: LSF System <lsfadmin@hpc.dtu.dk>
Subject: Job 22896750: <Segmentation> in cluster <dcc> Done

Job <Segmentation> was submitted from host <hpclogin1> by user <s204209> in cluster <dcc> at Wed Oct 23 14:18:42 2024
Job was executed on host(s) <4*n-62-18-8>, in queue <c02516>, as user <s204209> in cluster <dcc> at Wed Oct 23 14:18:43 2024
</zhome/e7/1/156531> was used as the home directory.
</zhome/e7/1/156531/02516/Segmentation_project/02516/Segmentation> was used as the working directory.
Started at Wed Oct 23 14:18:43 2024
Terminated at Wed Oct 23 14:20:07 2024
Results reported at Wed Oct 23 14:20:07 2024

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
#BSUB -J Segmentation
#BSUB -q c02516
#BSUB -gpu "num=1:mode=exclusive_process"
#BSUB -W 15
#BSUB -R "rusage[mem=4GB]"
#BSUB -o Segmentation.out
#BSUB -e Segmentation.err
#BSUB -R "span[hosts=1]"
#BSUB -n 4

# Initialize Python environment
source ../../../../02516_env/bin/activate

# Run Python script
python -m module.main
------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   77.72 sec.
    Max Memory :                                 243 MB
    Average Memory :                             240.67 MB
    Total Requested Memory :                     16384.00 MB
    Delta Memory :                               16141.00 MB
    Max Swap :                                   -
    Max Processes :                              4
    Max Threads :                                5
    Run time :                                   117 sec.
    Turnaround time :                            85 sec.

The output (if any) is above this job summary.



PS:

Read file <Segmentation.err> for stderr output of this job.

Device: cuda
* Epoch 1/30
 - loss: 0.657270
 - val_loss: 0.807093
* Epoch 2/30
 - loss: 0.621128
 - val_loss: 0.814957
* Epoch 3/30
 - loss: 0.578597
 - val_loss: 0.858817
* Epoch 4/30
 - loss: 0.471440
 - val_loss: 0.912029
* Epoch 5/30
 - loss: 0.445546
 - val_loss: 0.700740
* Epoch 6/30
 - loss: 0.437034
 - val_loss: 0.676616
* Epoch 7/30
 - loss: 0.419771
 - val_loss: 0.712044
* Epoch 8/30
 - loss: 0.412944
 - val_loss: 1.026704
* Epoch 9/30
 - loss: 0.366516
 - val_loss: 0.956653
* Epoch 10/30
 - loss: 0.309627
 - val_loss: 1.155400
* Epoch 11/30
 - loss: 0.252142
 - val_loss: 0.742429
* Epoch 12/30
 - loss: 0.200410
 - val_loss: 0.612841
* Epoch 13/30
 - loss: 0.179184
 - val_loss: 0.798563
* Epoch 14/30
 - loss: 0.218131
 - val_loss: 0.606012
* Epoch 15/30
 - loss: 0.199459
 - val_loss: 0.967777
* Epoch 16/30
 - loss: 0.188340
 - val_loss: 1.070140
* Epoch 17/30
 - loss: 0.213318
 - val_loss: 0.568665
* Epoch 18/30
 - loss: 0.175693
 - val_loss: 0.451178
* Epoch 19/30
 - loss: 0.155621
 - val_loss: 0.552062
* Epoch 20/30
 - loss: 0.152877
 - val_loss: 0.798494
* Epoch 21/30
 - loss: 0.157269
 - val_loss: 0.628463
* Epoch 22/30
 - loss: 0.147361
 - val_loss: 0.655330
* Epoch 23/30
 - loss: 0.131866
 - val_loss: 0.905813
* Epoch 24/30
 - loss: 0.146058
 - val_loss: 0.707868
* Epoch 25/30
 - loss: 0.149895
 - val_loss: 0.433626
* Epoch 26/30
 - loss: 0.131276
 - val_loss: 0.502778
* Epoch 27/30
 - loss: 0.132820
 - val_loss: 0.593131
* Epoch 28/30
 - loss: 0.128775
 - val_loss: 1.017566
* Epoch 29/30
 - loss: 0.136194
 - val_loss: 0.667468
* Epoch 30/30
 - loss: 0.130240
 - val_loss: 0.660659
* Epoch 1/30
 - loss: 0.593888
 - val_loss: 0.851801
* Epoch 2/30
 - loss: 0.515397
 - val_loss: 0.882796
* Epoch 3/30
 - loss: 0.489633
 - val_loss: 0.852751
* Epoch 4/30
 - loss: 0.412194
 - val_loss: 0.877164
* Epoch 5/30
 - loss: 0.283786
 - val_loss: 1.567577
* Epoch 6/30
 - loss: 0.281552
 - val_loss: 0.653435
* Epoch 7/30
 - loss: 0.221809
 - val_loss: 0.833359
* Epoch 8/30
 - loss: 0.194134
 - val_loss: 0.871421
* Epoch 9/30
 - loss: 0.199330
 - val_loss: 0.607457
* Epoch 10/30
 - loss: 0.192103
 - val_loss: 0.795076
* Epoch 11/30
 - loss: 0.205498
 - val_loss: 0.707583
* Epoch 12/30
 - loss: 0.210665
 - val_loss: 0.483407
* Epoch 13/30
 - loss: 0.199818
 - val_loss: 0.622029
* Epoch 14/30
 - loss: 0.206593
 - val_loss: 0.773037
* Epoch 15/30
 - loss: 0.154406
 - val_loss: 0.638921
* Epoch 16/30
 - loss: 0.149015
 - val_loss: 0.687973
* Epoch 17/30
 - loss: 0.148895
 - val_loss: 0.505809
* Epoch 18/30
 - loss: 0.136732
 - val_loss: 0.657460
* Epoch 19/30
 - loss: 0.139764
 - val_loss: 0.818930
* Epoch 20/30
 - loss: 0.199051
 - val_loss: 0.351965
* Epoch 21/30
 - loss: 0.153467
 - val_loss: 0.759836
* Epoch 22/30
 - loss: 0.155899
 - val_loss: 0.515416
* Epoch 23/30
 - loss: 0.144074
 - val_loss: 0.582858
* Epoch 24/30
 - loss: 0.139050
 - val_loss: 0.561917
* Epoch 25/30
 - loss: 0.140877
 - val_loss: 0.535602
* Epoch 26/30
 - loss: 0.144872
 - val_loss: 0.407455
* Epoch 27/30
 - loss: 0.136891
 - val_loss: 0.632102
* Epoch 28/30
 - loss: 0.123008
 - val_loss: 0.674291
* Epoch 29/30
 - loss: 0.126818
 - val_loss: 0.504248
* Epoch 30/30
 - loss: 0.123840
 - val_loss: 0.369394

------------------------------------------------------------
Sender: LSF System <lsfadmin@hpc.dtu.dk>
Subject: Job 22896759: <Segmentation> in cluster <dcc> Done

Job <Segmentation> was submitted from host <hpclogin1> by user <s204209> in cluster <dcc> at Wed Oct 23 14:21:35 2024
Job was executed on host(s) <4*n-62-18-8>, in queue <c02516>, as user <s204209> in cluster <dcc> at Wed Oct 23 14:21:35 2024
</zhome/e7/1/156531> was used as the home directory.
</zhome/e7/1/156531/02516/Segmentation_project/02516/Segmentation> was used as the working directory.
Started at Wed Oct 23 14:21:35 2024
Terminated at Wed Oct 23 14:23:02 2024
Results reported at Wed Oct 23 14:23:02 2024

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
#BSUB -J Segmentation
#BSUB -q c02516
#BSUB -gpu "num=1:mode=exclusive_process"
#BSUB -W 15
#BSUB -R "rusage[mem=4GB]"
#BSUB -o Segmentation.out
#BSUB -e Segmentation.err
#BSUB -R "span[hosts=1]"
#BSUB -n 4

# Initialize Python environment
source ../../../../02516_env/bin/activate

# Run Python script
python -m module.main
------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   76.42 sec.
    Max Memory :                                 834 MB
    Average Memory :                             649.00 MB
    Total Requested Memory :                     16384.00 MB
    Delta Memory :                               15550.00 MB
    Max Swap :                                   -
    Max Processes :                              4
    Max Threads :                                8
    Run time :                                   99 sec.
    Turnaround time :                            87 sec.

The output (if any) is above this job summary.



PS:

Read file <Segmentation.err> for stderr output of this job.

